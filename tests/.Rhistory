# Simple script to download articles from BMC Bioinformatics
library(XML)
library(httr)
library(openxlsx)
# returns string w/o leading whitespace
trim.leading <- function (x)  sub("^\\s+", "", x)
# returns string w/o trailing whitespace
trim.trailing <- function (x) sub("\\s+$", "", x)
# returns string w/o leading or trailing whitespace
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
url <- "https://egov.uscis.gov/casestatus/mycasestatus.do"
## Check status using list of case numbers
cases <- unlist(strsplit(readLines("/Users/ilya/Dropbox/EB/cases.txt"), "\n"))
d <- data.frame(matrix(NA, nrow=0, ncol=3))
for(c in cases) {
body <- list(appReceiptNum=c)
r <- POST(url=url, body = body, encode="multipart")
dat <- content(r, "text")
doc <- htmlParse(dat)
nodeFound <- xpathApply(doc, "//div[@class=\"current-status-sec\"]") #/html/body/pre/span[374]/a
val <- xmlValue(nodeFound[[1]])
nodeFoundExtn <- xpathApply(doc, "//div[@class=\"rows text-center\"]")
valExtn <- xmlValue(nodeFoundExtn[[1]])
rw <- data.frame(receipt=c, status=trim(unlist(strsplit(val, "\r\n\t        "))[3]), description=trim(unlist(strsplit(valExtn, "\r\n\t        "))[3]))
d <- rbind(d, rw)
print(rw[1:2])
free(doc)
Sys.sleep(3)
}
print(Sys.time())
library(haploR)
x <- LDlink.LDmatrix(snps=c("rs10048158","rs4791078"))
LDlink.LDmatrix
# Test vector of SNPs
x <- LDlink.LDmatrix(snps=c("rs10048158","rs4791078"))
?LDlink.LDmatrix
data <- LDlink.LDmatrix(c("rs10048158","rs4791078"))
data
data$matrix.r2
dim(data$matrix.r2)
head(data$matrix.r2)
head(data$matrix.dprime)
#### haploR settings###
# LDlink settings
LD.settings <- list(ldmatrix.url="https://analysistools.nci.nih.gov/LDlink/LDlinkRest/ldmatrix",
ldmatrix.file.r2.url="https://analysistools.nci.nih.gov/LDlink/tmp/r2_",
ldmatrix.file.dprime.url="https://analysistools.nci.nih.gov/LDlink/tmp/d_prime_",
avail.pop=c("YRI","LWK","GWD","MSL","ESN","ASW","ACB",
"MXL","PUR","CLM","PEL","CHB","JPT","CHS",
"CDX","KHV","CEU","TSI","FIN","GBR","IBS",
"GIH","PJL","BEB","STU","ITU",
"ALL", "AFR", "AMR", "EAS", "EUR", "SAS"),
avail.ld=c("r2", "d"))
# TODO - add other settings if needed
library(httr)
library(XML)
population="ALL"
snps=c("rs10048158","rs4791078")
url <- LD.settings[["ldmatrix.url"]]
avail.pop <- LD.settings[["avail.pop"]]
avail.ld <- LD.settings[["avail.ld"]]
file.r2.url <- LD.settings[["ldmatrix.file.r2.url"]]
file.dprime.url <- LD.settings[["ldmatrix.file.dprime.url"]]
r2d<-"r2"
# Checking parameters for validity
if(!(r2d %in% avail.ld)) {
stop("Not valid r2d")
}
if(!(population %in% avail.pop)) {
stop("Not valid population")
}
query <- c()
snps.to.upload <- c()
if(mode(snps) %in% c("logical","numeric","complex","character")) {
# Assume it is a file
if(length(snps) == 1) {
# Try to read data into lines
tryCatch({
snps.to.upload <- readLines(snps)
snps.to.upload <- gsub("\n", "", snps.to.upload)
snps.to.upload <- gsub("\r", "", snps.to.upload)
}, error=function(e) {
print(e)
stop()
}, warning=function(w) {
print(w)
})
query <- paste(snps.to.upload, collapse = '%0A')  # %0A - new line character '\n'
} else {
snps.to.upload <- snps
query <- paste(snps.to.upload, collapse = '%0A')  # %0A - new line character '\n'
}
}
query
snps.to.upload
reference <- floor(runif(1) * (99999 - 10000 + 1))
body <- list(paste("snps=",query, sep=""),
paste("pop=", population, sep=""),
paste("reference=",reference, sep=""),
paste("r2_d=","r2",sep=""))
t.url <- paste(url, "?", paste(unlist(body), collapse = "&"), sep="")
r <- GET(url=t.url)
body <- list(paste("snps=",query, sep=""),
paste("pop=", population, sep=""),
#paste("reference=",reference, sep=""),
paste("r2_d=","r2",sep=""))
t.url <- paste(url, "?", paste(unlist(body), collapse = "&"), sep="")
t.url
r <- GET(url=t.url)
r
reference <- floor(runif(1) * (99999 - 10000 + 1))
body <- list(paste("snps=",query, sep=""),
paste("pop=", population, sep=""),
paste("reference=",reference, sep=""),
paste("r2_d=","r2",sep=""))
t.url <- paste(url, "?", paste(unlist(body), collapse = "&"), sep="")
t.url
r <- GET(url=t.url)
# Download r2 data
file.r2.url <- paste(file.r2.url, reference, ".txt", sep="")
file.r2.url
raw.ldmat.r2 <- read.csv(file=file.r2.url, sep="\t")
raw.ldmat.r2
?GET
httr::set_config(config(ssl_verifypeer = 0L))
r <- GET(url=t.url)
r
reference <- floor(runif(1) * (99999 - 10000 + 1))
body <- list(paste("snps=",query, sep=""),
paste("pop=", population, sep=""),
paste("reference=",reference, sep=""),
paste("r2_d=","r2",sep=""))
t.url <- paste(url, "?", paste(unlist(body), collapse = "&"), sep="")
httr::set_config(config(ssl_verifypeer = 0L, ssl_verifyhost = 0L))
r <- GET(url=t.url)
# Download r2 data
file.r2.url <- paste(file.r2.url, reference, ".txt", sep="")
raw.ldmat.r2 <- read.csv(file=file.r2.url, sep="\t")
# Download D prime data
file.dprime.url <- paste(file.dprime.url, reference, ".txt", sep="")
raw.ldmat.r2
r
#### haploR settings###
# LDlink settings
LD.settings <- list(ldmatrix.url="https://analysistools.nci.nih.gov/LDlink/LDlinkRest/ldmatrix",
ldmatrix.file.r2.url="https://ldlink.nci.nih.gov/tmp/r2_", #ldmatrix.file.r2.url="https://analysistools.nci.nih.gov/LDlink/tmp/r2_",
ldmatrix.file.dprime.url="https://ldlink.nci.nih.gov/tmp/d_prime_", # ldmatrix.file.dprime.url="https://analysistools.nci.nih.gov/LDlink/tmp/d_prime_"
avail.pop=c("YRI","LWK","GWD","MSL","ESN","ASW","ACB",
"MXL","PUR","CLM","PEL","CHB","JPT","CHS",
"CDX","KHV","CEU","TSI","FIN","GBR","IBS",
"GIH","PJL","BEB","STU","ITU",
"ALL", "AFR", "AMR", "EAS", "EUR", "SAS"),
avail.ld=c("r2", "d"))
# TODO - add other settings if needed
# Download r2 data
file.r2.url <- paste(file.r2.url, reference, ".txt", sep="")
raw.ldmat.r2 <- read.csv(file=file.r2.url, sep="\t")
raw.ldmat.r2
reference <- floor(runif(1) * (99999 - 10000 + 1))
body <- list(paste("snps=",query, sep=""),
paste("pop=", population, sep=""),
paste("reference=",reference, sep=""),
paste("r2_d=","r2",sep=""))
t.url <- paste(url, "?", paste(unlist(body), collapse = "&"), sep="")
httr::set_config(config(ssl_verifypeer = 0L, ssl_verifyhost = 0L))
r <- GET(url=t.url)
#dat <- content(r, "text")
# Download r2 data
file.r2.url <- paste(file.r2.url, reference, ".txt", sep="")
raw.ldmat.r2 <- read.csv(file=file.r2.url, sep="\t")
raw.ldmat.r2
#### haploR settings###
# LDlink settings
LD.settings <- list(ldmatrix.url="https://ldlink.nci.nih.gov/?tab=ldmatrix",#ldmatrix.url="https://analysistools.nci.nih.gov/LDlink/LDlinkRest/ldmatrix",
ldmatrix.file.r2.url="https://ldlink.nci.nih.gov/tmp/r2_", #ldmatrix.file.r2.url="https://analysistools.nci.nih.gov/LDlink/tmp/r2_",
ldmatrix.file.dprime.url="https://ldlink.nci.nih.gov/tmp/d_prime_", # ldmatrix.file.dprime.url="https://analysistools.nci.nih.gov/LDlink/tmp/d_prime_"
avail.pop=c("YRI","LWK","GWD","MSL","ESN","ASW","ACB",
"MXL","PUR","CLM","PEL","CHB","JPT","CHS",
"CDX","KHV","CEU","TSI","FIN","GBR","IBS",
"GIH","PJL","BEB","STU","ITU",
"ALL", "AFR", "AMR", "EAS", "EUR", "SAS"),
avail.ld=c("r2", "d"))
# TODO - add other settings if needed
url <- LD.settings[["ldmatrix.url"]]
avail.pop <- LD.settings[["avail.pop"]]
avail.ld <- LD.settings[["avail.ld"]]
file.r2.url <- LD.settings[["ldmatrix.file.r2.url"]]
file.dprime.url <- LD.settings[["ldmatrix.file.dprime.url"]]
r2d<-"r2"
# Checking parameters for validity
if(!(r2d %in% avail.ld)) {
stop("Not valid r2d")
}
if(!(population %in% avail.pop)) {
stop("Not valid population")
}
query <- c()
snps.to.upload <- c()
if(mode(snps) %in% c("logical","numeric","complex","character")) {
# Assume it is a file
if(length(snps) == 1) {
# Try to read data into lines
tryCatch({
snps.to.upload <- readLines(snps)
snps.to.upload <- gsub("\n", "", snps.to.upload)
snps.to.upload <- gsub("\r", "", snps.to.upload)
}, error=function(e) {
print(e)
stop()
}, warning=function(w) {
print(w)
})
query <- paste(snps.to.upload, collapse = '%0A')  # %0A - new line character '\n'
} else {
snps.to.upload <- snps
query <- paste(snps.to.upload, collapse = '%0A')  # %0A - new line character '\n'
}
}
reference <- floor(runif(1) * (99999 - 10000 + 1))
body <- list(paste("snps=",query, sep=""),
paste("pop=", population, sep=""),
paste("reference=",reference, sep=""),
paste("r2_d=","r2",sep=""))
t.url <- paste(url, "?", paste(unlist(body), collapse = "&"), sep="")
t.url
httr::set_config(config(ssl_verifypeer = 0L, ssl_verifyhost = 0L))
r <- GET(url=t.url)
r
# Download r2 data
file.r2.url <- paste(file.r2.url, reference, ".txt", sep="")
raw.ldmat.r2 <- read.csv(file=file.r2.url, sep="\t")
#### haploR settings###
# LDlink settings
LD.settings <- list(ldmatrix.url="https://analysistools.nci.nih.gov/LDlink/LDlinkRest/ldmatrix",
ldmatrix.file.r2.url="https://ldlink.nci.nih.gov/tmp/r2_", #ldmatrix.file.r2.url="https://analysistools.nci.nih.gov/LDlink/tmp/r2_",
ldmatrix.file.dprime.url="https://ldlink.nci.nih.gov/tmp/d_prime_", # ldmatrix.file.dprime.url="https://analysistools.nci.nih.gov/LDlink/tmp/d_prime_"
avail.pop=c("YRI","LWK","GWD","MSL","ESN","ASW","ACB",
"MXL","PUR","CLM","PEL","CHB","JPT","CHS",
"CDX","KHV","CEU","TSI","FIN","GBR","IBS",
"GIH","PJL","BEB","STU","ITU",
"ALL", "AFR", "AMR", "EAS", "EUR", "SAS"),
avail.ld=c("r2", "d"))
# TODO - add other settings if needed
url <- LD.settings[["ldmatrix.url"]]
avail.pop <- LD.settings[["avail.pop"]]
avail.ld <- LD.settings[["avail.ld"]]
file.r2.url <- LD.settings[["ldmatrix.file.r2.url"]]
file.dprime.url <- LD.settings[["ldmatrix.file.dprime.url"]]
r2d<-"r2"
# Checking parameters for validity
if(!(r2d %in% avail.ld)) {
stop("Not valid r2d")
}
if(!(population %in% avail.pop)) {
stop("Not valid population")
}
query <- c()
snps.to.upload <- c()
if(mode(snps) %in% c("logical","numeric","complex","character")) {
# Assume it is a file
if(length(snps) == 1) {
# Try to read data into lines
tryCatch({
snps.to.upload <- readLines(snps)
snps.to.upload <- gsub("\n", "", snps.to.upload)
snps.to.upload <- gsub("\r", "", snps.to.upload)
}, error=function(e) {
print(e)
stop()
}, warning=function(w) {
print(w)
})
query <- paste(snps.to.upload, collapse = '%0A')  # %0A - new line character '\n'
} else {
snps.to.upload <- snps
query <- paste(snps.to.upload, collapse = '%0A')  # %0A - new line character '\n'
}
}
reference <- floor(runif(1) * (99999 - 10000 + 1))
body <- list(paste("snps=",query, sep=""),
paste("pop=", population, sep=""),
paste("reference=",reference, sep=""),
paste("r2_d=","r2",sep=""))
t.url <- paste(url, "?", paste(unlist(body), collapse = "&"), sep="")
httr::set_config(config(ssl_verifypeer = 0L, ssl_verifyhost = 0L))
r <- GET(url=t.url)
#dat <- content(r, "text")
# Download r2 data
file.r2.url <- paste(file.r2.url, reference, ".txt", sep="")
raw.ldmat.r2 <- read.csv(file=file.r2.url, sep="\t")
#### haploR settings###
# LDlink settings
LD.settings <- list(ldmatrix.url="https://ldlink.nci.nih.gov/LDlinkRestWeb/ldmatrix", #"https://analysistools.nci.nih.gov/LDlink/LDlinkRest/ldmatrix",
ldmatrix.file.r2.url="https://ldlink.nci.nih.gov/tmp/r2_", #ldmatrix.file.r2.url="https://analysistools.nci.nih.gov/LDlink/tmp/r2_",
ldmatrix.file.dprime.url="https://ldlink.nci.nih.gov/tmp/d_prime_", # ldmatrix.file.dprime.url="https://analysistools.nci.nih.gov/LDlink/tmp/d_prime_"
avail.pop=c("YRI","LWK","GWD","MSL","ESN","ASW","ACB",
"MXL","PUR","CLM","PEL","CHB","JPT","CHS",
"CDX","KHV","CEU","TSI","FIN","GBR","IBS",
"GIH","PJL","BEB","STU","ITU",
"ALL", "AFR", "AMR", "EAS", "EUR", "SAS"),
avail.ld=c("r2", "d"))
# TODO - add other settings if needed
url <- LD.settings[["ldmatrix.url"]]
avail.pop <- LD.settings[["avail.pop"]]
avail.ld <- LD.settings[["avail.ld"]]
file.r2.url <- LD.settings[["ldmatrix.file.r2.url"]]
file.dprime.url <- LD.settings[["ldmatrix.file.dprime.url"]]
r2d<-"r2"
# Checking parameters for validity
if(!(r2d %in% avail.ld)) {
stop("Not valid r2d")
}
if(!(population %in% avail.pop)) {
stop("Not valid population")
}
query <- c()
snps.to.upload <- c()
if(mode(snps) %in% c("logical","numeric","complex","character")) {
# Assume it is a file
if(length(snps) == 1) {
# Try to read data into lines
tryCatch({
snps.to.upload <- readLines(snps)
snps.to.upload <- gsub("\n", "", snps.to.upload)
snps.to.upload <- gsub("\r", "", snps.to.upload)
}, error=function(e) {
print(e)
stop()
}, warning=function(w) {
print(w)
})
query <- paste(snps.to.upload, collapse = '%0A')  # %0A - new line character '\n'
} else {
snps.to.upload <- snps
query <- paste(snps.to.upload, collapse = '%0A')  # %0A - new line character '\n'
}
}
reference <- floor(runif(1) * (99999 - 10000 + 1))
body <- list(paste("snps=",query, sep=""),
paste("pop=", population, sep=""),
paste("reference=",reference, sep=""),
paste("r2_d=","r2",sep=""))
t.url <- paste(url, "?", paste(unlist(body), collapse = "&"), sep="")
httr::set_config(config(ssl_verifypeer = 0L, ssl_verifyhost = 0L))
r <- GET(url=t.url)
#dat <- content(r, "text")
# Download r2 data
file.r2.url <- paste(file.r2.url, reference, ".txt", sep="")
raw.ldmat.r2 <- read.csv(file=file.r2.url, sep="\t")
raw.ldmat.r2
devtools::document("~/Projects/haploR")
devtools::document("~/Projects/haploR")
# Simple script to download articles from BMC Bioinformatics
library(XML)
library(httr)
library(openxlsx)
# returns string w/o leading whitespace
trim.leading <- function (x)  sub("^\\s+", "", x)
# returns string w/o trailing whitespace
trim.trailing <- function (x) sub("\\s+$", "", x)
# returns string w/o leading or trailing whitespace
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
url <- "https://egov.uscis.gov/casestatus/mycasestatus.do"
## Check status using list of case numbers
cases <- unlist(strsplit(readLines("/Users/ilya/Dropbox/EB/cases.txt"), "\n"))
d <- data.frame(matrix(NA, nrow=0, ncol=3))
for(c in cases) {
body <- list(appReceiptNum=c)
r <- POST(url=url, body = body, encode="multipart")
dat <- content(r, "text")
doc <- htmlParse(dat)
nodeFound <- xpathApply(doc, "//div[@class=\"current-status-sec\"]") #/html/body/pre/span[374]/a
val <- xmlValue(nodeFound[[1]])
nodeFoundExtn <- xpathApply(doc, "//div[@class=\"rows text-center\"]")
valExtn <- xmlValue(nodeFoundExtn[[1]])
rw <- data.frame(receipt=c, status=trim(unlist(strsplit(val, "\r\n\t        "))[3]), description=trim(unlist(strsplit(valExtn, "\r\n\t        "))[3]))
d <- rbind(d, rw)
print(rw[1:2])
free(doc)
Sys.sleep(3)
}
print(Sys.time())
